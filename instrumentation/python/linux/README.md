# Instrumenting a Python Application with OpenTelemetry

This example demonstrates how to instrument a Python application using OpenTelemetry,
and export traces, metrics, and logs to a local collector, which will then
export that data to Splunk. We'll use Python 3.12 for this example, but the steps
for other Python versions are similar.

## Prerequisites

The following tools are required to build and execute the Python application:

* Python 3.12+
* A Linux-compatible host (such as Ubuntu 24.04, or Mac OS)

## Deploy the Splunk OpenTelemetry Collector

This example requires the Splunk Distribution of the OpenTelemetry collector to
be running on the host and available via http://localhost:4317.  Follow the
instructions in [Install the Collector for Linux with the installer script](https://docs.splunk.com/observability/en/gdi/opentelemetry/collector-linux/install-linux.html#install-the-collector-using-the-installer-script)
to install the collector on your host.

## Instrument and Execute the Application

Open a command line terminal and navigate to the root of the directory, 
then create a virtual environment an activate it: 

````
cd ~/splunk-opentelemetry-examples/instrumentation/python/linux
python3 -m venv venv
source ./venv/bin/activate
````

### Prep Package Installation and Instrumentation (Optional)

We installed the following packages: 

````
pip3 install flask
pip3 install "splunk-opentelemetry[all]" 
````

We then ran the following command to install instrumentation for packages 
used by our application: 

````
splunk-py-trace-bootstrap
````

We then generated a requirements.txt file by executing the following command:

````
pip3 freeze > requirements.txt
````

There's no need to run these commands again as you can use the `requirements.txt` file that
was already created.

### Install Packages

Use the following command to install the required packages, which includes those 
used for OpenTelemetry instrumentation: 

````
pip3 install -r requirements.txt
````

### Set Environment Variables

To configure the instrumentation, we've set the following environment variables:

```` 
export OTEL_SERVICE_NAME=python-flask-otel
export OTEL_RESOURCE_ATTRIBUTES='deployment.environment=test'
export SPLUNK_PROFILER_ENABLED=true
````

Note that we've enabled both the CPU profiler, so we can utilize the
AlwaysOn Profiling capabilities.

### Execute the application

Next, we'll execute the application with the `splunk-py-trace` binary as follows:

````
splunk-py-trace flask run -p 8080
````

Access the application by navigating your web browser to the following URL:

````
http://localhost:8080/hello
````

You should receive the following response:

````
Hello, World! 
````

### View Traces in Splunk Observability Cloud

After a minute or so, you should start to see traces for the Python application
appearing in Splunk Observability Cloud:

![Trace](./images/trace.png)

### View AlwaysOn Profiling Data in Splunk Observability Cloud

You should also see profiling data appear:

![AlwaysOn Profiling Data](./images/profiling.png)

### View Metrics in Splunk Observability Cloud

Metrics are collected by the Splunk Distribution of OpenTelemetry Python automatically.  For example,
the `process.runtime.cpython.memory` metric shows us the amount of memory used by the
Python process:

![Python Runtime Metric Example](./images/metrics.png)

### View Logs with Trace Context

The Splunk Distribution of OpenTelemetry Python automatically adds trace context
to logs when the standard `logging` library is used. 

Here's an example log entry, which includes the trace_id and span_id:

````
2024-11-20 09:44:23,884 INFO [app] [app.py:11] [trace_id=1e16f688e4b6fc2c09a00c7522ca4c7a span_id=ae92e28b8c2007b0 resource.service.name=python-flask-otel trace_sampled=True] - Handling the /hello request
````

The OpenTelemetry Collector can be configured to export log data to
Splunk platform using the Splunk HEC exporter.  The logs can then be made
available to Splunk Observability Cloud using Log Observer Connect.  This will
provide full correlation between spans generated by Python instrumentation
with metrics and logs. 